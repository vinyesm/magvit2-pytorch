# -*- coding: utf-8 -*-
"""toy-example-autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vy51dM62GPWF7Zy_nrRZcSgKB3Ugx1UB
"""

#https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/

#TODO
#add channels like in https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/08-deep-autoencoders.ipynb#scrollTo=cf346a22

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install webdataset

import torch
import matplotlib.pyplot as plt

torch.cuda.get_device_name(0)

import torch
from torch import nn
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader, RandomSampler
import webdataset as wds
from random import random

from magvit2_pytorch import (
    VideoTokenizer,
    VideoTokenizerTrainer
)

# dataset_folder = "images.tar.gz"
train_dataset_paths = "toy-data/shard{1..7}.tar.gz::toy-data/shard{1..7}.tar.gz"
valid_dataset_paths = "toy-data/shard{8..9}.tar.gz"

class RandomApply(nn.Module):
    def __init__(self, prob, fn, fn_else = lambda x: x):
        super().__init__()
        self.fn = fn
        self.fn_else = fn_else
        self.prob = prob
    def forward(self, x):
        fn = self.fn if random() < self.prob else self.fn_else
        return fn(x)

transform = transforms.Compose([
    transforms.Resize(32),
    RandomApply(0.1, transforms.RandomResizedCrop(32, scale=(0.5, 1.0), ratio=(0.98, 1.02)), transforms.CenterCrop(32)),
    transforms.ToTensor()
])



batch_size = 32
num_workers = 1
train_ds = wds.WebDataset(train_dataset_paths).decode("pilrgb").rename(image="jpg;png;jpeg;webp").map_dict(image=transform).to_tuple("image").shuffle(800)
train_dataloader = wds.WebLoader(train_ds, batch_size=batch_size, num_workers=num_workers)

valid_ds = wds.WebDataset(valid_dataset_paths).decode("pilrgb").rename(image="jpg;png;jpeg;webp").map_dict(image=transform).to_tuple("image")
valid_dl = wds.WebLoader(valid_ds, batch_size=batch_size, num_workers=num_workers)

# import torchvision.transforms as transforms
# from torch.utils.data import DataLoader
# from torchvision.datasets import FashionMNIST

# batch_size = 32

# img_transform = transforms.Compose([
#     transforms.ToTensor(),
#     # transforms.Normalize((0.5,), (0.5,))
# ])

# train_dataset = FashionMNIST(root='./data/FashionMNIST', download=True, train=True, transform=img_transform)
# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# test_dataset = FashionMNIST(root='./data/FashionMNIST', download=True, train=False, transform=img_transform)
# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

# from torchvision import datasets

# # Transforms images to a PyTorch Tensor
# tensor_transform = transforms.ToTensor()

# # Download the MNIST Dataset
# dataset = datasets.MNIST(root = "./data",
#                          train = True,
#                          download = True,
#                          transform = tensor_transform)

# # DataLoader is used to load the dataset
# # for training
# train_dataloader = torch.utils.data.DataLoader(dataset = dataset,
#                                      batch_size = 32,
#                                      shuffle = True)

class Reshape(torch.nn.Module):
  def __init__(self, *args):
    super().__init__()
    self.shape = args

  def forward(self, x):
    return x.view(self.shape)

# Creating a PyTorch class
# 32*32 ==> 9 ==> 32*32
class AE(torch.nn.Module):
	def __init__(self):
		super().__init__()

		# Building an linear encoder with Linear
		# layer followed by Relu activation function
		# 784 ==> 9
		self.encoder = torch.nn.Sequential(
			torch.nn.Linear(32*32, 32*32),
		)



	def forward(self, x):
		encoded = self.encoder(x)
		# decoded = self.decoder(encoded)
		decoded = encoded
		return decoded

# Model Initialization
model = VideoTokenizer(
    image_size = 32,
    init_dim = 16,
    max_dim = 32,
    codebook_size = 1024, # 1024
    layers = (
        # 'residual',
        # 'compress_space',
        # ('consecutive_residual', 2),
        # 'linear_attend_space',
        # 'compress_space',
        # ('consecutive_residual', 2),
        # 'attend_space',
    ),
    perceptual_loss_weight = 0.,
    adversarial_loss_weight = 0.,
    quantizer_aux_loss_weight = 0.,
    use_gan = False
)

# Validation using MSE Loss function
loss_function = torch.nn.MSELoss()

# Using an Adam Optimizer with lr = 0.1
optimizer = torch.optim.Adam(model.parameters(),
                             lr = 1e-3,
                             weight_decay = 1e-8)

import numpy as np
import os

def save_img_recon(count, img, rec, directory_path = "./results"):
  # Concatenate the original and reconstructed images horizontally
  img = image.reshape(-1, 32, 32)
  rec = reconstructed.reshape(-1, 32, 32).detach().numpy()
  combined_image = np.concatenate((img[0], rec[0]), axis=1)

  if not os.path.exists(directory_path):
    # Create the directory if it doesn't exist
    os.makedirs(directory_path)

  # Save the combined image
  plt.imsave(f'{directory_path}/{count}.png', combined_image)

epochs = 20
outputs = []
losses = []
count = 0

for epoch in range(epochs):
  print(f"-------- epoch {epoch}")
  # for (image, _) in train_dataloader:
  for image in train_dataloader:
    image = image[0]
    # Reshaping the image to (-1, 784)
    # image = image.reshape(-1, 32*32)
    image = image.view(-1, 3, 1, 32, 32)

    # Output of Autoencoder
    reconstructed = model(image)

    # Calculating the loss function
    loss = loss_function(reconstructed, image)

    if count % 100 == 0:
      print(f"count: {count}, loss: {loss}")
      save_img_recon(count, image, reconstructed, "./results_pokemon")

    # The gradients are set to zero,
    # the gradient is computed and stored.
    # .step() performs parameter update
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # # Storing the losses in a list for plotting
    # losses.append(loss)
    # outputs.append((epochs, image, reconstructed))

    count += 1

# # Defining the Plot Style
# plt.style.use('fivethirtyeight')
# plt.xlabel('Iterations')
# plt.ylabel('Loss')

# # Plotting the last 100 values
# plt.plot(losses[-100:])



